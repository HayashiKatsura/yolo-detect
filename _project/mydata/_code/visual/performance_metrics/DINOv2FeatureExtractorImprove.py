import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import os

def safe_save_results(improved_labels, base_dir="./"):
    """
    å®‰å…¨ä¿å­˜æ”¹è¿›ç»“æœï¼Œå¹¶éªŒè¯ä¿å­˜æ˜¯å¦æˆåŠŸ
    """
    print("=== ä¿å­˜æ”¹è¿›ç»“æœ ===")
    
    # 1. ç¡®ä¿ç›®å½•å­˜åœ¨
    save_dir = os.path.join(base_dir, "clustering_results")
    os.makedirs(save_dir, exist_ok=True)
    print(f"ä¿å­˜ç›®å½•: {os.path.abspath(save_dir)}")
    
    # 2. å®šä¹‰æ–‡ä»¶è·¯å¾„
    improved_labels_path = os.path.join(save_dir, "improved_labels.npy")
    
    try:
        # 3. ä¿å­˜æ–‡ä»¶
        np.save(improved_labels_path, improved_labels)
        print(f"âœ… å°è¯•ä¿å­˜åˆ°: {os.path.abspath(improved_labels_path)}")
        
        # 4. éªŒè¯ä¿å­˜æ˜¯å¦æˆåŠŸ
        if os.path.exists(improved_labels_path):
            # å°è¯•é‡æ–°åŠ è½½éªŒè¯
            test_load = np.load(improved_labels_path)
            if len(test_load) == len(improved_labels):
                print(f"âœ… ä¿å­˜æˆåŠŸï¼æ–‡ä»¶å¤§å°: {len(test_load)} ä¸ªæ ‡ç­¾")
                print(f"âœ… æ–‡ä»¶ä½ç½®: {os.path.abspath(improved_labels_path)}")
                return improved_labels_path
            else:
                print(f"âŒ ä¿å­˜å¤±è´¥ï¼šæ–‡ä»¶å†…å®¹ä¸åŒ¹é…")
        else:
            print(f"âŒ ä¿å­˜å¤±è´¥ï¼šæ–‡ä»¶ä¸å­˜åœ¨")
            
    except Exception as e:
        print(f"âŒ ä¿å­˜å‡ºé”™: {e}")
    
    # 5. å¤‡ç”¨ä¿å­˜æ–¹æ¡ˆï¼šä¿å­˜åˆ°å½“å‰ç›®å½•
    backup_path = "improved_labels_backup.npy"
    try:
        np.save(backup_path, improved_labels)
        print(f"ğŸ”„ å¤‡ç”¨ä¿å­˜: {os.path.abspath(backup_path)}")
        return backup_path
    except Exception as e:
        print(f"âŒ å¤‡ç”¨ä¿å­˜ä¹Ÿå¤±è´¥: {e}")
        return None

def compare_clustering_results(original_labels, improved_labels, features_pca):
    """
    å¯¹æ¯”åŸå§‹å’Œæ”¹è¿›çš„èšç±»ç»“æœ
    """
    print("\n=== èšç±»ç»“æœå¯¹æ¯” ===")
    
    # 1. åŸºæœ¬ç»Ÿè®¡å¯¹æ¯”
    orig_clusters = len(np.unique(original_labels))
    impr_clusters = len(np.unique(improved_labels))
    
    print(f"åŸå§‹èšç±»æ•°: {orig_clusters}")
    print(f"æ”¹è¿›èšç±»æ•°: {impr_clusters}")
    
    # 2. è´¨é‡æŒ‡æ ‡å¯¹æ¯”
    orig_silhouette = silhouette_score(features_pca, original_labels)
    impr_silhouette = silhouette_score(features_pca, improved_labels)
    
    print(f"\nè´¨é‡å¯¹æ¯”:")
    print(f"åŸå§‹è½®å»“ç³»æ•°: {orig_silhouette:.3f}")
    print(f"æ”¹è¿›è½®å»“ç³»æ•°: {impr_silhouette:.3f}")
    
    if impr_silhouette > orig_silhouette:
        improvement = ((impr_silhouette - orig_silhouette) / orig_silhouette) * 100
        print(f"âœ… æ”¹è¿›äº† {improvement:.1f}%")
    else:
        decline = ((orig_silhouette - impr_silhouette) / orig_silhouette) * 100
        print(f"âŒ ä¸‹é™äº† {decline:.1f}%")
    
    # 3. èšç±»å¤§å°åˆ†å¸ƒå¯¹æ¯”
    print(f"\nèšç±»å¤§å°åˆ†å¸ƒå¯¹æ¯”:")
    print("åŸå§‹:")
    orig_unique, orig_counts = np.unique(original_labels, return_counts=True)
    for cluster_id, count in zip(orig_unique, orig_counts):
        percentage = count / len(original_labels) * 100
        print(f"  Cluster {cluster_id}: {count} ({percentage:.1f}%)")
    
    print("æ”¹è¿›:")
    impr_unique, impr_counts = np.unique(improved_labels, return_counts=True)
    for cluster_id, count in zip(impr_unique, impr_counts):
        percentage = count / len(improved_labels) * 100
        print(f"  Cluster {cluster_id}: {count} ({percentage:.1f}%)")

def create_comparison_visualization(original_labels, improved_labels, features_2d, save_path=None):
    """
    åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–å›¾
    """
    print("\n=== ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ– ===")
    
    # åˆ›å»ºå¹¶æ’å¯¹æ¯”å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # åŸå§‹èšç±»å›¾
    n_orig_clusters = len(np.unique(original_labels))
    colors1 = plt.cm.Set3(np.linspace(0, 1, n_orig_clusters))
    
    for i in range(n_orig_clusters):
        mask = original_labels == i
        ax1.scatter(features_2d[mask, 0], features_2d[mask, 1], 
                   c=[colors1[i]], label=f'Cluster {i}', alpha=0.7, s=30)
    
    ax1.set_title('åŸå§‹èšç±»ç»“æœ (6ç±»)', fontsize=14)
    ax1.set_xlabel('t-SNE dimension 1')
    ax1.set_ylabel('t-SNE dimension 2')
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax1.grid(True, alpha=0.3)
    
    # æ”¹è¿›èšç±»å›¾
    n_impr_clusters = len(np.unique(improved_labels))
    colors2 = plt.cm.Set3(np.linspace(0, 1, n_impr_clusters))
    
    for i in range(n_impr_clusters):
        mask = improved_labels == i
        ax2.scatter(features_2d[mask, 0], features_2d[mask, 1], 
                   c=[colors2[i]], label=f'Cluster {i}', alpha=0.7, s=30)
    
    ax2.set_title(f'æ”¹è¿›èšç±»ç»“æœ ({n_impr_clusters}ç±»)', fontsize=14)
    ax2.set_xlabel('t-SNE dimension 1')
    ax2.set_ylabel('t-SNE dimension 2')
    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    if save_path:
        try:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… å¯¹æ¯”å›¾ä¿å­˜åˆ°: {os.path.abspath(save_path)}")
        except Exception as e:
            backup_path = "clustering_comparison.png"
            plt.savefig(backup_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ”„ å¯¹æ¯”å›¾å¤‡ç”¨ä¿å­˜: {os.path.abspath(backup_path)}")
    
    plt.show()

def use_improved_labels_workflow():
    """
    ä½¿ç”¨æ”¹è¿›æ ‡ç­¾çš„å®Œæ•´å·¥ä½œæµç¨‹
    """
    print("=== æ”¹è¿›æ ‡ç­¾ä½¿ç”¨æŒ‡å— ===\n")
    
    try:
        # 1. åŠ è½½åŸå§‹æ•°æ®
        print("1. åŠ è½½åŸå§‹æ•°æ®...")
        original_labels = np.load('/home/panxiang/coding/kweilx/ultralytics/_project/mydata/_a_datasets/anomolies/1480èšç±»åˆ†æ/labels.npy')
        features_2d = np.load('/home/panxiang/coding/kweilx/ultralytics/_project/mydata/_a_datasets/anomolies/1480èšç±»åˆ†æ/features_2d.npy')
        features = np.load('/home/panxiang/coding/kweilx/ultralytics/_project/mydata/_a_datasets/anomolies/1480èšç±»åˆ†æ/features.npy')
        
        # 2. é‡æ–°ç”ŸæˆPCAç‰¹å¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
        print("2. å¤„ç†ç‰¹å¾æ•°æ®...")
        from sklearn.decomposition import PCA
        pca = PCA(n_components=50)
        features_normalized = (features - features.mean(axis=0)) / features.std(axis=0)
        features_pca = pca.fit_transform(features_normalized)
        
        # 3. ç”Ÿæˆæ”¹è¿›çš„èšç±»ï¼ˆç¤ºä¾‹ï¼šä½¿ç”¨8ä¸ªèšç±»ï¼‰
        print("3. ç”Ÿæˆæ”¹è¿›èšç±»...")
        improved_kmeans = KMeans(n_clusters=8, random_state=42, n_init=10)
        improved_labels = improved_kmeans.fit_predict(features_pca)
        
        # 4. å®‰å…¨ä¿å­˜
        print("4. ä¿å­˜æ”¹è¿›ç»“æœ...")
        saved_path = safe_save_results(improved_labels)
        
        if saved_path:
            # 5. å¯¹æ¯”åˆ†æ
            print("5. å¯¹æ¯”åˆ†æ...")
            compare_clustering_results(original_labels, improved_labels, features_pca)
            
            # 6. ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–
            print("6. ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–...")
            create_comparison_visualization(
                original_labels, improved_labels, features_2d,
                save_path="/home/panxiang/coding/kweilx/ultralytics/_project/mydata/_a_datasets/anomolies/1480èšç±»åˆ†æ/clustering_comparison.png"
            )
            
            print(f"\n{'='*50}")
            print("ğŸ‰ æ”¹è¿›æµç¨‹å®Œæˆï¼")
            print(f"{'='*50}")
            print("ç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"- æ”¹è¿›æ ‡ç­¾: {saved_path}")
            print(f"- å¯¹æ¯”å›¾: clustering_comparison.png")
            print("\nç°åœ¨ä½ å¯ä»¥:")
            print("1. æŸ¥çœ‹å¯¹æ¯”å›¾ï¼Œæ¯”è¾ƒæ–°æ—§èšç±»æ•ˆæœ")
            print("2. å¦‚æœæ»¡æ„ï¼Œä½¿ç”¨æ–°æ ‡ç­¾é‡æ–°ç»„ç»‡å›¾åƒæ–‡ä»¶å¤¹")
            print("3. å¦‚æœä¸æ»¡æ„ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹æ ‡ç­¾")
            
            return improved_labels, saved_path
        else:
            print("âŒ ä¿å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™å’Œè·¯å¾„")
            return None, None
            
    except FileNotFoundError as e:
        print(f"âŒ æ‰¾ä¸åˆ°åŸå§‹æ•°æ®æ–‡ä»¶: {e}")
        print("è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨:")
        print("- clustering_results/labels.npy")
        print("- clustering_results/features_2d.npy") 
        print("- clustering_results/features.npy")
        return None, None
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹å‡ºé”™: {e}")
        return None, None

def reorganize_images_with_improved_labels(improved_labels_path, original_image_paths, output_dir="/home/panxiang/coding/kweilx/ultralytics/_project/mydata/_a_datasets/anomolies/1480èšç±»åˆ†æ"):
    """
    ä½¿ç”¨æ”¹è¿›çš„æ ‡ç­¾é‡æ–°ç»„ç»‡å›¾åƒæ–‡ä»¶
    """
    print(f"\n=== ä½¿ç”¨æ”¹è¿›æ ‡ç­¾é‡æ–°ç»„ç»‡å›¾åƒ ===")
    
    try:
        # åŠ è½½æ”¹è¿›çš„æ ‡ç­¾
        improved_labels = np.load(improved_labels_path)
        print(f"âœ… åŠ è½½æ”¹è¿›æ ‡ç­¾: {len(improved_labels)} ä¸ªæ ‡ç­¾")
        
        # åˆ›å»ºæ–°çš„è¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¸ºæ¯ä¸ªæ–°èšç±»åˆ›å»ºç›®å½•
        unique_labels = np.unique(improved_labels)
        for label in unique_labels:
            cluster_dir = os.path.join(output_dir, f"cluster_{label}")
            os.makedirs(cluster_dir, exist_ok=True)
        
        # å¤åˆ¶å›¾åƒåˆ°æ–°çš„èšç±»ç›®å½•
        import shutil
        for img_path, label in zip(original_image_paths, improved_labels):
            if os.path.exists(img_path):
                filename = os.path.basename(img_path)
                dst_path = os.path.join(output_dir, f"cluster_{label}", filename)
                shutil.copy2(img_path, dst_path)
        
        print(f"âœ… å›¾åƒé‡æ–°ç»„ç»‡å®Œæˆï¼")
        print(f"âœ… æ–°çš„èšç±»æ–‡ä»¶å¤¹: {os.path.abspath(output_dir)}")
        
        # ç»Ÿè®¡æ¯ä¸ªèšç±»çš„å›¾åƒæ•°é‡
        for label in unique_labels:
            cluster_dir = os.path.join(output_dir, f"cluster_{label}")
            count = len(os.listdir(cluster_dir))
            print(f"   Cluster {label}: {count} å¼ å›¾åƒ")
            
    except Exception as e:
        print(f"âŒ é‡æ–°ç»„ç»‡å›¾åƒå¤±è´¥: {e}")

# ä¸»å‡½æ•°ï¼šå®Œæ•´çš„ä½¿ç”¨æµç¨‹
def main():
    """
    å®Œæ•´çš„æ”¹è¿›èšç±»ä½¿ç”¨æµç¨‹
    """
    print("å¼€å§‹æ”¹è¿›èšç±»åˆ†æ...\n")
    
    # è¿è¡Œæ”¹è¿›æµç¨‹
    improved_labels, saved_path = use_improved_labels_workflow()
    
    if improved_labels is not None and saved_path is not None:
        print(f"\næˆåŠŸï¼ç°åœ¨ä½ æœ‰äº†æ”¹è¿›çš„èšç±»ç»“æœã€‚")
        print(f"æ”¹è¿›æ ‡ç­¾æ–‡ä»¶: {saved_path}")
        
        # è¯¢é—®æ˜¯å¦è¦é‡æ–°ç»„ç»‡å›¾åƒæ–‡ä»¶
        # reorganize = input("\næ˜¯å¦è¦ç”¨æ–°æ ‡ç­¾é‡æ–°ç»„ç»‡å›¾åƒæ–‡ä»¶å¤¹ï¼Ÿ(y/n): ")
        # if reorganize.lower() == 'y':
        #     # è¿™é‡Œéœ€è¦ä½ æä¾›åŸå§‹å›¾åƒè·¯å¾„åˆ—è¡¨
        #     # image_paths = [...] # ä½ çš„å›¾åƒè·¯å¾„åˆ—è¡¨
        #     # reorganize_images_with_improved_labels(saved_path, image_paths)

if __name__ == "__main__":
    main()