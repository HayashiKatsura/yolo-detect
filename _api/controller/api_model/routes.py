from . import api_model

from flask import Flask, request, jsonify
from ...services.YOLOTrainingManager import get_training_manager
from flask import Flask, request, jsonify
from flask_cors import CORS
import threading
import pandas as pd
import os
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from ultralytics import YOLO, RTDETR
from _api.services.YoloAPI import YoloAPI
from _api._utils.ResultsResponse.NoStandardResponse import NoStandardResponse
from _api.entity.ResponseCode import ResponseCode

# from _project.mydata._code.yolo._test import standard_test

# project_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
# import sys
# sys.path.append(project_path)

# é…ç½®æ—¥å¿—
# import logging
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger(__name__)
from loguru import logger
logger.remove()

"""
yoloç›¸å…³
"""
@api_model.route('/training/start', methods=['POST'])
def start_training():
    """å¯åŠ¨è®­ç»ƒAPI"""
    try:
        config = request.json
        logger.info(f"ğŸ“‹ æ”¶åˆ°è®­ç»ƒé…ç½®: {config}")
        
        manager = get_training_manager()
        session_id, success, message, save_dir,save_folder_id = manager.start_training(config)
        
        return jsonify({
            'success': success,
            'session_id': session_id,
            'message': message,
            'save_dir': save_dir,
            'save_folder_id': save_folder_id
        })
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨è®­ç»ƒå¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'message': f'å¯åŠ¨å¤±è´¥: {str(e)}'
        }), 500

@api_model.route('/training/stop/<session_id>', methods=['POST'])
def stop_training(session_id):
    """åœæ­¢è®­ç»ƒå¹¶é‡ç½®çŠ¶æ€"""
    try:
        manager = get_training_manager()
        success, message = manager.stop_training(session_id)
        
        # è‡ªåŠ¨é‡ç½®çŠ¶æ€
        if session_id in manager.active_processes:
            del manager.active_processes[session_id]
            logger.info(f"ğŸ§¹ è‡ªåŠ¨é‡ç½®ä¼šè¯çŠ¶æ€: {session_id}")
        
        return jsonify({
            'success': success,
            'message': message,
            'auto_reset': True
        })
        
    except Exception as e:
        logger.error(f"åœæ­¢è®­ç»ƒå¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'message': f'åœæ­¢å¤±è´¥: {str(e)}'
        }), 500

@api_model.route('/training/status', methods=['GET'])
@api_model.route('/training/status/<session_id>', methods=['GET'])
def get_training_status(session_id=None):
    """è·å–è®­ç»ƒçŠ¶æ€API"""
    try:
        manager = get_training_manager()
        status = manager.get_training_status(session_id)
        
        return jsonify({
            'success': True,
            'data': status
        })
        
    except Exception as e:
        logger.error(f"è·å–çŠ¶æ€å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'message': f'è·å–çŠ¶æ€å¤±è´¥: {str(e)}'
        }), 500

@api_model.route('/training/progress/<session_id>', methods=['GET'])
def get_training_progress(session_id):
    """è·å–è®­ç»ƒè¿›åº¦API"""
    try:
        manager = get_training_manager()
        progress = manager.get_latest_progress(session_id)
        
        session_info = manager.get_training_status(session_id)
        debug_info = {
            'session_exists': session_id in manager.active_processes,
            'csv_path': session_info.get('csv_path') if session_info else None,
            'status': session_info.get('status') if session_info else None
        }
        
        return jsonify({
            'success': True,
            'data': progress,
            'debug': debug_info
        })
        
    except Exception as e:
        logger.error(f"âŒ è·å–è¿›åº¦å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'message': f'è·å–è¿›åº¦å¤±è´¥: {str(e)}'
        }), 500

@api_model.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥API"""
    try:
        manager = get_training_manager()
        return jsonify({
            'success': True,
            'message': 'YOLOè®­ç»ƒæœåŠ¡å™¨è¿è¡Œæ­£å¸¸',
            'active_sessions': len(manager.active_processes),
            'sessions': list(manager.active_processes.keys())
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}'
        }), 500

@api_model.route('/debug/<session_id>', methods=['GET'])
def debug_session(session_id):
    """è°ƒè¯•ä¼šè¯ä¿¡æ¯"""
    try:
        training_manager = get_training_manager()
        session_info = training_manager.get_training_status(session_id)
        
        debug_data = {
            'session_id': session_id,
            'session_exists': session_id in training_manager.active_processes,
            'all_sessions': list(training_manager.active_processes.keys()),
            'session_info': session_info,
            'csv_monitors': training_manager.csv_monitors,
        }
        
        if session_info:
            debug_data['session_details'] = {
                'status': session_info.get('status'),
                'start_time': session_info.get('start_time'),
                'csv_path': session_info.get('csv_path'),
                'latest_data': session_info.get('latest_data'),
                'save_dir': session_info.get('save_dir')
            }
            
            csv_path = session_info.get('csv_path')
            if csv_path:
                debug_data['csv_info'] = {
                    'path': csv_path,
                    'exists': os.path.exists(csv_path),
                    'size': os.path.getsize(csv_path) if os.path.exists(csv_path) else 0,
                    'modified_time': os.path.getmtime(csv_path) if os.path.exists(csv_path) else 0
                }
                
                if os.path.exists(csv_path):
                    try:
                        df = pd.read_csv(csv_path)
                        debug_data['csv_content'] = {
                            'rows': len(df),
                            'columns': list(df.columns),
                            'last_few_rows': df.tail(3).to_dict('records') if len(df) > 0 else []
                        }
                    except Exception as e:
                        debug_data['csv_error'] = str(e)
            
            save_dir = session_info.get('save_dir')
            if save_dir:
                debug_data['save_dir_info'] = {
                    'path': save_dir,
                    'exists': os.path.exists(save_dir),
                    'files': []
                }
                
                if os.path.exists(save_dir):
                    try:
                        files = os.listdir(save_dir)
                        debug_data['save_dir_info']['files'] = files
                        csv_files = [f for f in files if f.endswith('.csv')]
                        debug_data['save_dir_info']['csv_files'] = csv_files
                    except Exception as e:
                        debug_data['save_dir_info']['error'] = str(e)
        
        return jsonify({
            'success': True,
            'debug_data': debug_data
        })
        
    except Exception as e:
        logger.error(f"è°ƒè¯•å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@api_model.route('/force_csv_scan/<session_id>', methods=['POST'])
def force_csv_scan(session_id):
    """å¼ºåˆ¶æ‰«æCSVæ–‡ä»¶"""
    try:
        training_manager = get_training_manager()
        if session_id not in training_manager.active_processes:
            return jsonify({
                'success': False,
                'message': 'ä¼šè¯ä¸å­˜åœ¨'
            }), 404
        
        session_info = training_manager.active_processes[session_id]
        save_dir = session_info.get('save_dir')
        
        if save_dir:
            logger.info(f"ğŸ” å¼ºåˆ¶æ‰«æCSVæ–‡ä»¶,ç›®å½•: {save_dir}")
            
            threading.Thread(
                target=training_manager._enhanced_csv_monitoring,
                args=(session_id, session_info.get('params', {})),
                daemon=True
            ).start()
            
            return jsonify({
                'success': True,
                'message': 'å·²é‡æ–°æ‰«æCSVæ–‡ä»¶',
                'csv_path': session_info.get('csv_path')
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æ²¡æœ‰ä¿å­˜ç›®å½•ä¿¡æ¯'
            })
            
    except Exception as e:
        logger.error(f"CSVæ‰«æå¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'message': f'æ‰«æå¤±è´¥: {str(e)}'
        }), 500

@api_model.route('/training/zip/<session_id>', methods=['POST'])
def zip_training_results(session_id):
    """æ‰‹åŠ¨å‹ç¼©è®­ç»ƒç»“æœ"""
    try:
        manager = get_training_manager()
        
        if session_id not in manager.active_processes:
            return jsonify({
                'success': False,
                'message': 'è®­ç»ƒä¼šè¯ä¸å­˜åœ¨'
            }), 404
        
        session_info = manager.active_processes[session_id]
        save_dir = session_info.get('save_dir')
        
        if not save_dir:
            return jsonify({
                'success': False,
                'message': 'æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒä¿å­˜ç›®å½•'
            }), 400
        
        zip_path = manager._auto_zip_training_results(save_dir)
        
        if zip_path:
            return jsonify({
                'success': True,
                'message': 'å‹ç¼©å®Œæˆ',
                'zip_path': zip_path,
                'save_dir': save_dir
            })
        else:
            return jsonify({
                'success': False,
                'message': 'å‹ç¼©å¤±è´¥'
            }), 500
            
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨å‹ç¼©å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'message': f'å‹ç¼©å¤±è´¥: {str(e)}'
        }), 500


@api_model.route('/detect_file', methods=['GET'], strict_slashes=False)
def detect_image():
    """
    é¢„æµ‹å›¾åƒ
    """
    weight_id = request.args.get('weight_id')
    image_id = request.args.get('image_id')
    images_id = request.args.get('images_id',None)
    camera = request.args.get('camera',False)
    if images_id and images_id!='null':
        image_id = images_id
    conf = float(request.args.get('conf'))
    results = YoloAPI(weight_id,conf,camera=camera).detect_file(image_id)
    return jsonify(NoStandardResponse(ResponseCode.success.value, "success", data=results).get_response_body())
          
@api_model.route("/progress/<file_id>", methods=["GET"])
def video_detect_progress(file_id):
    """
    è§†é¢‘æ£€æµ‹è¿›åº¦
    """
    results = YoloAPI(None).detect_progress(file_id)
    return jsonify(NoStandardResponse(ResponseCode.success.value, "success", data=results).get_response_body())

@api_model.route('/val_weight/<weight_id>', methods=['GET'], strict_slashes=False)
def val_weight(weight_id):
    """
    éªŒè¯æƒé‡
    """
    dataYamlId = request.args.get('dataYamlId')
    conf = float(request.args.get('conf'))
    results = YoloAPI(weight_id,conf).val_weight(dataYamlId)
    return jsonify(NoStandardResponse(ResponseCode.success.value, "success", data=results).get_response_body())
 


@api_model.route('/valid_params/<file_id>', methods=['GET'], strict_slashes=False)
def valid_params(file_id):
    """
    å‚æ•°æ ¡éªŒ
    """
    results = YoloAPI(None).validate(file_id)
    return jsonify(NoStandardResponse(ResponseCode.success.value, "success", data=results).get_response_body())

 
 
 
 
 
 
# @api_model.route("/api/progress/<task_id>", methods=["GET"]) # TODO
# def video_detect_progress(task_id):
#     """
#     è§†é¢‘æ£€æµ‹è¿›åº¦
#     """
#     progress = processing_progress.get(task_id, -1)
#     return jsonify({"code": 200, "progress": progress})

 



# # TODO ZWX æ–°å¢
# import base64
# import io
# import cv2
# import numpy as np
# from PIL import Image
# import time
# import tempfile
# from datetime import timedelta
# import csv
# import uuid
# from flask import Flask, request, jsonify,send_from_directory,make_response



# # addæ‘„åƒå¤´å®æ—¶æ£€æµ‹
# # å…¨å±€æ¨¡å‹å­˜å‚¨,é¿å…é‡å¤åŠ è½½

# model = None
# target_classes = [0, 1 , 2]  # ç›®æ ‡ç±»åˆ«

# def init_model():
#     global model
#     if model is None:
#         model_path = "/home/panxiang/coding/kweilx/ultralytics/zwx.pt"
#         # ç¬¬ä¸€æ­¥ï¼šå…ˆéªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
#         if not os.path.exists(model_path):
#             raise Exception(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼è·¯å¾„ï¼š{model_path}")
        
#         model = YOLO(model_path)  # å…³é”®ï¼šæ·»åŠ deviceå‚æ•°
#         print(f"æ¨¡å‹åŠ è½½æˆåŠŸ,ä½¿ç”¨è®¾å¤‡: {model.device}")  
# # å¯åŠ¨æ—¶åˆå§‹åŒ–æ¨¡å‹
# init_model()
# @api_model.route('/detect_camera', methods=['POST'])
# def detect_camera():
#     # å¤„ç†æ‘„åƒå¤´å®æ—¶æ£€æµ‹è¯·æ±‚(ä½¿ç”¨ç»å¯¹è·¯å¾„åŠ è½½çš„å›ºå®šæ¨¡å‹
#     try:
#                 # æ—¥å¿—1ï¼šç¡®è®¤æ¥å£è¢«è°ƒç”¨
#         print("\n=== æ”¶åˆ° /zjut/detect_camera è¯·æ±‚ ===")
#         # å£ç½©ï¼Œå®‰å…¨å¸½
#         model_path = "/home/panxiang/coding/kweilx/ultralytics/safety_helmet.pt"

#         # åŠ è½½æ¨¡å‹
#         print("å¼€å§‹åŠ è½½æ¨¡å‹...")
#         print(f"æ¨¡å‹åŠ è½½æˆåŠŸ,ä½¿ç”¨è®¾å¤‡: {model.device}")  
#         # model = YOLO(model_path,device=0)
#         print("æ¨¡å‹åŠ è½½å®Œæˆ")
#         # æ‰§è¡Œé¢„æµ‹
#         print("å¼€å§‹æ‰§è¡Œé¢„æµ‹...")
#         # results = model.predict(image_path, classes=[0,2], save=True)
#         print("é¢„æµ‹æ‰§è¡Œå®Œæˆ")
#         # 1. è·å–è¯·æ±‚æ•°æ®
#         data = request.json
#         print("è¯·æ±‚æ•°æ®æ˜¯å¦å­˜åœ¨:", "æ˜¯" if data else "å¦")  # æ—¥å¿—2
#         if not data or 'frame' not in data:
#             print("é”™è¯¯ï¼šç¼ºå°‘frameå‚æ•°")  # æ—¥å¿—3
#             return jsonify({
#                 'status': 'error',
#                 'message': 'ç¼ºå°‘å¿…è¦å‚æ•°: frame'
#             }), 400
#         # 2. è§£æå‚æ•°(åŸä»£ç åŸºç¡€ä¸Šè¡¥å……æ—¥å¿—ï¼‰
#         print("è¯·æ±‚æ•°æ®ä¸­çš„æ‰€æœ‰å­—æ®µ:", data.keys())  # æ–°å¢æ—¥å¿—ï¼šæŸ¥çœ‹dataé‡Œæ˜¯å¦æœ‰frame
#         if 'frame' not in data:
#             print("é”™è¯¯ï¼šç¼ºå°‘frameå‚æ•°")
#             return jsonify({'status':'error','message':'ç¼ºå°‘å¿…è¦å‚æ•°: frame'}),400

#         frame_data = data['frame']
#         conf_threshold = data.get('conf', 0.25)
#         # æ–°å¢æ—¥å¿—ï¼šæŸ¥çœ‹frameé•¿åº¦(æœ‰æ•ˆBase64è‡³å°‘å‡ åƒå­—ç¬¦,ç©ºå­—ç¬¦ä¸²æˆ–çŸ­å­—ç¬¦ä¸²éƒ½æ˜¯æ— æ•ˆçš„ï¼‰
#         print(f"frameå‚æ•°é•¿åº¦: {len(frame_data)} å­—ç¬¦")  
#                 # è·å–è¯·æ±‚æ•°æ®
#         data = request.json
#         if not data or 'frame' not in data:
#             return jsonify({
#                 'status': 'error',
#                 'message': 'ç¼ºå°‘å¿…è¦å‚æ•°: frame'
#             }), 400

#         # è§£æå‚æ•°
#         frame_data = data['frame']  # Base64æ ¼å¼å›¾åƒ
#         conf_threshold = data.get('conf', 0.25)  # ç½®ä¿¡åº¦é˜ˆå€¼,é»˜è®¤0.25

#         # è§£æBase64å›¾åƒ
#         try:
#             # å»é™¤Base64å‰ç¼€
#             if ',' in frame_data:
#                 frame_data = frame_data.split(',')[1]
#                 print("å·²å»é™¤Base64å‰ç¼€,å¤„ç†åé•¿åº¦:", len(frame_data))
            
#             # è§£ç Base64
#             img_bytes = base64.b64decode(frame_data)
#             print(f"Base64è§£ç æˆåŠŸ,å¾—åˆ° {len(img_bytes)} å­—èŠ‚çš„å›¾åƒæ•°æ®")


#             img = Image.open(io.BytesIO(img_bytes))
#             print(f"å›¾åƒè§£ææˆåŠŸï¼šå°ºå¯¸ {img.size},æ ¼å¼ {img.format}")
#             img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
#             print("å·²è½¬æ¢ä¸ºOpenCVæ ¼å¼,å‡†å¤‡æ¨ç†")
#         except Exception as e:
#             return jsonify({
#                 'status': 'error',
#                 'message': f'å›¾åƒè§£æå¤±è´¥: {str(e)}'
#             }), 400

#         # æ¨¡å‹æ¨ç†
#         print(f"\n===== å¼€å§‹æ¨¡å‹æ¨ç† =====")
#         print(f"æ¨¡å‹æ˜¯å¦åŠ è½½: {'æ˜¯' if model is not None else 'å¦(æ¨¡å‹ä¸ºNoneï¼ï¼‰'}")  # å…³é”®ï¼šç¡®è®¤æ¨¡å‹å·²åŠ è½½
#         print(f"è¾“å…¥å›¾åƒå°ºå¯¸: {img_cv.shape}(é«˜xå®½xé€šé“æ•°,åº”ä¸1280x720å¯¹åº”ï¼‰")
#         print(f"ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
#         print(f"ä½¿ç”¨è®¾å¤‡: {model.device}")  # éªŒè¯æ¨ç†æ—¶çš„è®¾å¤‡
#         start_time = time.time()
#         results = model(img_cv, conf=conf_threshold,classes=target_classes)
#         infer_time = round((time.time() - start_time) * 1000, 2)  # æ¨ç†æ—¶é—´(ms)
#         print(f"æ¨ç†è€—æ—¶: {infer_time} ms")

#           # éªŒè¯æ¨ç†ç»“æœç»“æ„
#         print(f"æ¨ç†è¿”å›ç»“æœæ•°é‡: {len(results)}(æ­£å¸¸åº”ä¸º1,å¯¹åº”å•å¸§å›¾åƒï¼‰")
#         if len(results) == 0:
#             print("é”™è¯¯ï¼šæ¨¡å‹è¿”å›ç©ºç»“æœ(æœªå¤„ç†å›¾åƒï¼‰")
#             return jsonify({
#                 'status': 'error',
#                 'message': 'æ¨¡å‹æœªè¿”å›ä»»ä½•æ¨ç†ç»“æœ'
#             }), 500

#         result = results[0]
#         print(f"ç¬¬ä¸€å¸§ç»“æœåŒ…å«çš„ç›®æ ‡æ•°é‡: {len(result.boxes)}")  # å…³é”®ï¼šæ˜¯å¦æœ‰æ£€æµ‹åˆ°ç›®æ ‡
#         if len(result.boxes) > 0:
#             box = result.boxes[0]
#             print(f"ç¬¬ä¸€ä¸ªç›®æ ‡ä¿¡æ¯:")
#             print(f"  ç±»åˆ«ID: {int(box.cls[0])}")
#             print(f"  ç±»åˆ«åç§°: {model.names[int(box.cls[0])]}")  # éªŒè¯ç±»åˆ«åç§°æ˜¯å¦å­˜åœ¨
#             print(f"  ç½®ä¿¡åº¦: {float(box.conf[0]):.2f}")
#             print(f"  åæ ‡(x1,y1,x2,y2): {box.xyxy[0].tolist()}")
#         # å¤„ç†æ£€æµ‹ç»“æœ
#         detections = []
#         for result in results:
#             for box in result.boxes:
#                 x1, y1, x2, y2 = box.xyxy[0].tolist()
#                 cls_name = model.names[int(box.cls[0])]
#                 confidence = float(box.conf[0])
#                 detections.append({
#                     'class': cls_name,
#                     'confidence': round(confidence, 2),
#                     'bbox': [round(x1), round(y1), round(x2), round(y2)],
#                     'inference_time': infer_time
#                 })
#         print(f"æœ€ç»ˆæå–çš„æ£€æµ‹ç»“æœæ•°é‡: {len(detections)}")  # ç¡®è®¤ç»“æœåˆ—è¡¨éç©º
#         print(f"å‡†å¤‡è¿”å›çš„å“åº”æ•°æ®: {detections}")  # æ‰“å°å®Œæ•´ç»“æœ,ç¡®è®¤æ ¼å¼æ­£ç¡®

#         return jsonify({
#             'status': 'success',
#             'detections': detections,
#             'timestamp': int(time.time() * 1000)
#         })

#     except Exception as e:
#         return jsonify({
#             'status': 'error',
#             'message': f'æ£€æµ‹è¿‡ç¨‹å‡ºé”™: {str(e)}'
#         }), 500
    
    
    
# æ–°å¢,å¤„ç†è§†é¢‘æ–‡ä»¶è¯†åˆ«è¯·æ±‚
# @api_model.route('/detect_video', methods=['POST'])
# def detect_video():
#     # å¤„ç†è§†é¢‘æ–‡ä»¶è¯†åˆ«è¯·æ±‚
#     print("\n=== æ”¶åˆ° /zjut/detect_video è¯·æ±‚ ===")
#     try:
#         # è·å–è¯·æ±‚å‚æ•°
#         data = request.json
#         if not data or 'video_data' not in data:
#             return jsonify({
#                 'status': 'error',
#                 'message': 'ç¼ºå°‘å¿…è¦å‚æ•°: video_data'
#             }), 400

#         # è§£æå‚æ•°
#         video_base64 = data['video_data']
#         conf_threshold = data.get('conf', 0.25)
#         frame_interval = data.get('frame_interval', 10)  # æ¯éš”å¤šå°‘å¸§å¤„ç†ä¸€æ¬¡
#         max_frames = data.get('max_frames', 1000)  # æœ€å¤§å¤„ç†å¸§æ•°,é˜²æ­¢å†…å­˜æº¢å‡º

#         # è§£ç Base64è§†é¢‘æ•°æ®
#         try:
#             if ',' in video_base64:
#                 video_base64 = video_base64.split(',')[1]
#             video_bytes = base64.b64decode(video_base64)
#             logger.info(f"è§†é¢‘æ•°æ®è§£ç æˆåŠŸ,å¤§å°: {len(video_bytes)} bytes")
#         except Exception as e:
#             return jsonify({
#                 'status': 'error',
#                 'message': f'è§†é¢‘è§£ç å¤±è´¥: {str(e)}'
#             }), 400

#         # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å­˜å‚¨è§†é¢‘
#         with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_file:
#             temp_file.write(video_bytes)
#             temp_video_path = temp_file.name

#         # åˆå§‹åŒ–è§†é¢‘æ•è·
#         cap = cv2.VideoCapture(temp_video_path)
#         if not cap.isOpened():
#             os.unlink(temp_video_path)
#             return jsonify({
#                 'status': 'error',
#                 'message': 'æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶'
#             }), 400

#         # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
#         frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#         fps = cap.get(cv2.CAP_PROP_FPS)
#         width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#         height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

#         logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: æ€»å¸§æ•°={frame_count}, FPS={fps}, åˆ†è¾¨ç‡={width}x{height}")

#         # å¤„ç†è§†é¢‘å¸§
#         results = []
#         frame_idx = 0
#         processed_frames = 0
        
#         while cap.isOpened() and processed_frames < max_frames:
#             ret, frame = cap.read()
#             if not ret:
#                 break

#             # æŒ‰é—´éš”å¤„ç†å¸§
#             if frame_idx % frame_interval == 0:
#                 start_time = time.time()
                
#                 # è½¬æ¢ä¸ºRGBæ ¼å¼(YOLOæ¨¡å‹è¦æ±‚ï¼‰
#                 frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
#                 # æ¨¡å‹æ¨ç†
#                 detections = model(frame_rgb, conf=conf_threshold, classes=target_classes)
                
#                 # å¤„ç†æ£€æµ‹ç»“æœ
#                 frame_results = []
#                 for det in detections:
#                     for box in det.boxes:
#                         x1, y1, x2, y2 = box.xyxy[0].tolist()
#                         cls_name = model.names[int(box.cls[0])]
#                         confidence = float(box.conf[0])
#                         frame_results.append({
#                             'class': cls_name,
#                             'confidence': round(confidence, 2),
#                             'bbox': [round(x1), round(y1), round(x2), round(y2)]
#                         })
                
#                 # è®¡ç®—æ—¶é—´æˆ³(æ¯«ç§’ï¼‰
#                 timestamp = int((frame_idx / fps) * 1000)
                
#                 results.append({
#                     'frame_index': frame_idx,
#                     'timestamp': timestamp,
#                     'detections': frame_results,
#                     'inference_time': round((time.time() - start_time) * 1000, 2)
#                 })
                
#                 processed_frames += 1
#                 logger.debug(f"å¤„ç†å¸§ {frame_idx}/{frame_count}, æ£€æµ‹åˆ° {len(frame_results)} ä¸ªç›®æ ‡")

#             frame_idx += 1

#         # é‡Šæ”¾èµ„æº
#         cap.release()
#         os.unlink(temp_video_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶

#         logger.info(f"è§†é¢‘å¤„ç†å®Œæˆ,å…±å¤„ç† {processed_frames} å¸§")

#         return jsonify({
#             'status': 'success',
#             'video_info': {
#                 'total_frames': frame_count,
#                 'fps': fps,
#                 'resolution': f"{width}x{height}",
#                 'processed_frames': processed_frames
#             },
#             'results': results,
#             'timestamp': int(time.time() * 1000)
#         })

#     except Exception as e:
#         logger.error(f"è§†é¢‘è¯†åˆ«å‡ºé”™: {str(e)}")
#         return jsonify({
#             'status': 'error',
#             'message': f'è§†é¢‘å¤„ç†è¿‡ç¨‹å‡ºé”™: {str(e)}'
#         }), 500

# def load_model():
#     global model
#     if model is None:
#         model_path = "/home/panxiang/coding/kweilx/ultralytics/zwx.pt"
#         # ç¬¬ä¸€æ­¥ï¼šå…ˆéªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
#         if not os.path.exists(model_path):
#             raise Exception(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼è·¯å¾„ï¼š{model_path}")
        
#         model = YOLO(model_path)  # å…³é”®ï¼šæ·»åŠ deviceå‚æ•°
#         print(f"æ¨¡å‹åŠ è½½æˆåŠŸ,ä½¿ç”¨è®¾å¤‡: {model.device}")  
# # å¯åŠ¨æ—¶åˆå§‹åŒ–æ¨¡å‹
# load_model()

# # æ–‡ä»¶å¤¹é…ç½®
# UPLOAD_FOLDER = "/home/panxiang/coding/kweilx/ultralytics/uploads"
# OUTPUT_FOLDER = "/home/panxiang/coding/kweilx/ultralytics/outputs"
# os.makedirs(UPLOAD_FOLDER, exist_ok=True)
# os.makedirs(OUTPUT_FOLDER, exist_ok=True)
# processing_progress = {}   # ä»»åŠ¡è¿›åº¦å­˜å‚¨
# # æ–°å¢ï¼šæ‰“å°å®Œæ•´è·¯å¾„(å…³é”®ï¼‰
# print("åŸå§‹è§†é¢‘æ–‡ä»¶å¤¹å®Œæ•´è·¯å¾„ï¼š", os.path.abspath(UPLOAD_FOLDER))
# print("ç»“æœè§†é¢‘æ–‡ä»¶å¤¹å®Œæ•´è·¯å¾„ï¼š", os.path.abspath(OUTPUT_FOLDER))



# def generate_target_csv(task_id, target_frames, fps, output_folder):
    
#     # åŒä¸€ç›®æ ‡(åŒç±»åˆ«+è¿ç»­å¸§ï¼‰çš„æ£€æµ‹æ®µ,ä»…ä¿ç•™ä¸€ä¸ªä¸­é—´æ—¶é—´å†™å…¥CSV
    
#     # æ­¥éª¤1ï¼šæŒ‰å¸§ç´¢å¼•æ’åº,ç¡®ä¿å¸§é¡ºåºæ­£ç¡®
#     target_frames.sort(key=lambda x: x["frame_idx"])
#     if not target_frames:
#         return

#     # æ­¥éª¤2ï¼šè¯†åˆ«â€œåŒä¸€ç›®æ ‡(ç±»åˆ«+è¿ç»­å¸§ï¼‰â€çš„æ£€æµ‹æ®µ
#     target_segments = []  # å­˜å‚¨ç›®æ ‡æ®µï¼š[{start_idx, end_idx, class, start_ms, end_ms, mid_frame}, ...]
    
#     # åˆå§‹åŒ–ç¬¬ä¸€ä¸ªç›®æ ‡æ®µ(æŒ‰å¸§å†…æ¯ä¸ªç›®æ ‡åˆ†åˆ«åˆå§‹åŒ–ï¼‰
#     first_frame = target_frames[0]
#     for det in first_frame["detections"]:
#         target_segments.append({
#             "class": det["class"],  # ç›®æ ‡ç±»åˆ«(æ ¸å¿ƒï¼šæŒ‰ç±»åˆ«åŒºåˆ†åŒä¸€ç›®æ ‡ï¼‰
#             "start_idx": first_frame["frame_idx"],
#             "end_idx": first_frame["frame_idx"],
#             "start_ms": first_frame["timestamp_ms"],
#             "end_ms": first_frame["timestamp_ms"],
#             "frames": [first_frame]  # å­˜å‚¨è¯¥ç›®æ ‡æ®µçš„æ‰€æœ‰å¸§
#         })

#     # éå†åç»­å¸§,æ‰©å±•æˆ–æ–°å¢ç›®æ ‡æ®µ
#     for frame in target_frames[1:]:
#         current_frame_idx = frame["frame_idx"]
#         current_frame_dets = {det["class"]: det for det in frame["detections"]}  # æŒ‰ç±»åˆ«å­˜å‚¨å½“å‰å¸§ç›®æ ‡

#         # 1. å¤„ç†å·²æœ‰ç›®æ ‡æ®µï¼šåˆ¤æ–­å½“å‰å¸§æ˜¯å¦æœ‰åŒç±»åˆ«ç›®æ ‡ä¸”å¸§è¿ç»­
#         updated_segments = []
#         for seg in target_segments:
#             seg_class = seg["class"]
#             # åˆ¤å®šï¼šå½“å‰å¸§æœ‰åŒç±»åˆ«ç›®æ ‡ + å¸§è¿ç»­(å½“å‰å¸§ç´¢å¼•=æ®µç»“æŸå¸§+1ï¼‰
#             if seg_class in current_frame_dets and current_frame_idx == seg["end_idx"] + 1:
#                 # æ‰©å±•ç›®æ ‡æ®µï¼šæ›´æ–°ç»“æŸå¸§ã€ç»“æŸæ—¶é—´ã€æ·»åŠ å½“å‰å¸§
#                 seg["end_idx"] = current_frame_idx
#                 seg["end_ms"] = frame["timestamp_ms"]
#                 seg["frames"].append(frame)
#                 updated_segments.append(seg)
#                 # ä»å½“å‰å¸§ç›®æ ‡ä¸­ç§»é™¤å·²åŒ¹é…çš„ç±»åˆ«(é¿å…é‡å¤å¤„ç†ï¼‰
#                 del current_frame_dets[seg_class]
#             else:
#                 # ç›®æ ‡æ®µä¸è¿ç»­æˆ–æ— åŒç±»åˆ«ç›®æ ‡,ä¿ç•™åŸæ®µ
#                 updated_segments.append(seg)
#         target_segments = updated_segments

#         # 2. å¤„ç†å½“å‰å¸§ä¸­æœªåŒ¹é…çš„æ–°ç›®æ ‡(æ–°å¢ç›®æ ‡æ®µï¼‰
#         for det_class, det in current_frame_dets.items():
#             target_segments.append({
#                 "class": det_class,
#                 "start_idx": current_frame_idx,
#                 "end_idx": current_frame_idx,
#                 "start_ms": frame["timestamp_ms"],
#                 "end_ms": frame["timestamp_ms"],
#                 "frames": [frame]
#             })

#     # æ­¥éª¤3ï¼šè¿‡æ»¤æŒç»­æ—¶é—´ < 1ç§’(1000æ¯«ç§’ï¼‰çš„ç›®æ ‡æ®µ
#     filtered_segments = []
#     for seg in target_segments:
#         seg_duration_ms = seg["end_ms"] - seg["start_ms"]
#         if seg_duration_ms >= 1000:  # ä»…ä¿ç•™æŒç»­â‰¥1ç§’çš„ç›®æ ‡æ®µ
#             filtered_segments.append(seg)
#     if not filtered_segments:
#         print(f"ä»»åŠ¡ {task_id}ï¼šæ— æŒç»­â‰¥1ç§’çš„ç›®æ ‡æ®µ,ä¸ç”ŸæˆCSV")
#         return

#     # æ­¥éª¤4ï¼šæ—¶é—´æˆ³æ ¼å¼è½¬æ¢(æ¯«ç§’â†’åˆ†:ç§’.æ¯«ç§’ï¼‰
#     def format_time(ms):
#         td = timedelta(milliseconds=ms)
#         minutes = int(td.total_seconds() // 60)
#         seconds = int(td.total_seconds() % 60)
#         ms_remain = td.microseconds // 1000
#         return f"{minutes:02d}:{seconds:02d}.{ms_remain:03d}"

#     # æ­¥éª¤5ï¼šç”ŸæˆCSV(åŒä¸€ç›®æ ‡æ®µä»…å†™å…¥ä¸€ä¸ªä¸­é—´æ—¶é—´ï¼‰
#     csv_filename = f"{task_id}_target_timeline.csv"
#     csv_path = os.path.join(output_folder, csv_filename)

#     with open(csv_path, mode="w", newline="", encoding="utf-8") as f:
#         fieldnames = [
#             "ç›®æ ‡æ®µID", "ç›®æ ‡ç±»åˆ«", "ä¸­é—´å¸§æ—¶é—´", 
#             "ä¸­é—´å¸§ç´¢å¼•", "ç›®æ ‡ç½®ä¿¡åº¦", "æŒç»­æ—¶é—´(ç§’)"
#         ]
#         writer = csv.DictWriter(f, fieldnames=fieldnames)
#         writer.writeheader()

#         # éå†è¿‡æ»¤åçš„ç›®æ ‡æ®µ,æ¯ä¸ªæ®µä»…å†™å…¥ä¸€æ¡ä¸­é—´æ—¶é—´è®°å½•
#         for seg_id, seg in enumerate(filtered_segments, 1):
#             # è®¡ç®—å½“å‰ç›®æ ‡æ®µçš„ä¸­é—´å¸§
#             mid_idx = (seg["start_idx"] + seg["end_idx"]) // 2
#             # æ‰¾åˆ°ä¸­é—´å¸§æ•°æ®(å–ä¸­é—´å¸§ä¸­è¯¥ç±»åˆ«çš„ç›®æ ‡ç½®ä¿¡åº¦ï¼‰
#             mid_frame = next(f for f in seg["frames"] if f["frame_idx"] == mid_idx)
#             mid_det = next(d for d in mid_frame["detections"] if d["class"] == seg["class"])
#             # è®¡ç®—ä¸­é—´æ—¶é—´å’ŒæŒç»­æ—¶é—´
#             mid_time = format_time(mid_frame["timestamp_ms"])
#             duration_sec = round((seg["end_ms"] - seg["start_ms"]) / 1000, 2)

#             # åŒä¸€ç›®æ ‡æ®µä»…å†™å…¥ä¸€æ¡è®°å½•(å«å”¯ä¸€ä¸­é—´æ—¶é—´ï¼‰
#             writer.writerow({
#                 "ç›®æ ‡æ®µID": seg_id,
#                 "ç›®æ ‡ç±»åˆ«": seg["class"],
#                 "ä¸­é—´å¸§æ—¶é—´": mid_time,  # åŒä¸€ç›®æ ‡æ®µä»…ä¸€ä¸ªä¸­é—´æ—¶é—´
#                 "ä¸­é—´å¸§ç´¢å¼•": mid_idx,
#                 "ç›®æ ‡ç½®ä¿¡åº¦": round(mid_det["confidence"], 2),
#                 "æŒç»­æ—¶é—´(ç§’)": duration_sec
#             })

#     print(f"ä»»åŠ¡ {task_id}ï¼šCSVç”Ÿæˆå®Œæˆ,å…±{len(filtered_segments)}ä¸ªç›®æ ‡æ®µ(æ¯æ®µä¸€ä¸ªä¸­é—´æ—¶é—´ï¼‰,è·¯å¾„ï¼š{csv_path}")
    
# def process_video(video_path, output_path, task_id):
#     target_frames = []  # è®°å½•å«ç›®æ ‡(ç½®ä¿¡åº¦â‰¥0.3ï¼‰çš„å¸§
#     cap = cv2.VideoCapture(video_path)
#     fps = cap.get(cv2.CAP_PROP_FPS)
#     width, height = int(cap.get(3)), int(cap.get(4))
#     total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))   
    
#     # åˆå§‹åŒ–è§†é¢‘å†™å…¥å™¨(H.264ç¼–ç ,åˆ†è¾¨ç‡å¶æ•°å¤„ç†ï¼‰
#     fourcc = cv2.VideoWriter_fourcc(*"avc1")
#     width = width if width % 2 == 0 else width - 1
#     height = height if height % 2 == 0 else height - 1
#     out = cv2.VideoWriter(output_path, fourcc, fps, (width, height), isColor=True)
    
#     frame_count = 0
#     while cap.isOpened():
#         ret, frame = cap.read()
#         if not ret: break
        
#         # è°ƒæ•´å¸§å¤§å°(ä¸è¾“å‡ºè§†é¢‘ä¸€è‡´ï¼‰
#         if frame.shape[1] != width or frame.shape[0] != height:
#             frame = cv2.resize(frame, (width, height))
        
#         # æ¨¡å‹æ£€æµ‹(ç½®ä¿¡åº¦â‰¥0.3,è¿‡æ»¤ä½ç½®ä¿¡ç›®æ ‡ï¼‰
#         results = model(frame, conf=0.3)
#         annotated_frame = results[0].plot()
        
#         # è®°å½•å«ç›®æ ‡(ç½®ä¿¡åº¦â‰¥0.3ï¼‰çš„å¸§ä¿¡æ¯
#         frame_detections = []
#         for box in results[0].boxes:
#             det_conf = float(box.conf[0])
#             if det_conf >= 0.3:  # ä»…ä¿ç•™ç½®ä¿¡åº¦â‰¥0.3çš„ç›®æ ‡
#                 frame_detections.append({
#                     "class": model.names[int(box.cls[0])],
#                     "confidence": det_conf
#                 })
#         if frame_detections:  # ä»…å½“å¸§å«æœ‰æ•ˆç›®æ ‡æ—¶è®°å½•
#             target_frames.append({
#                 "frame_idx": frame_count,
#                 "timestamp_ms": int((frame_count / fps) * 1000),
#                 "detections": frame_detections
#             })

#         # å†™å…¥æ ‡æ³¨è§†é¢‘ + æ›´æ–°å¤„ç†è¿›åº¦
#         out.write(annotated_frame)
#         frame_count += 1
#         processing_progress[task_id] = min(int((frame_count / total_frames) * 100), 100)
    
#     # è§†é¢‘å¤„ç†å®Œæˆå,ç”ŸæˆCSV(ç¡®ä¿ä»…æ‰§è¡Œä¸€æ¬¡ï¼‰
#     if target_frames:
#         generate_target_csv(task_id, target_frames, fps, OUTPUT_FOLDER)
#     else:
#         print(f"ä»»åŠ¡ {task_id}ï¼šæœªæ£€æµ‹åˆ°ç½®ä¿¡åº¦â‰¥0.3çš„ç›®æ ‡,ä¸ç”ŸæˆCSV")
    
#     # é‡Šæ”¾èµ„æº(é¿å…æ–‡ä»¶å ç”¨ï¼‰
#     cap.release()
#     out.release()
#     cv2.destroyAllWindows()
#     # æ¥å£éƒ¨åˆ†(ä¸å˜,ç¡®ä¿å‰ç«¯èƒ½æ­£å¸¸ä¸Šä¼ ã€æŸ¥è¿›åº¦ã€å–ç»“æœï¼‰
# @api_model.route("/api/upload", methods=["POST"]) # TODO
# def upload_video():
#     if "video" not in request.files:
#         return jsonify({"code": 400, "msg": "æœªé€‰æ‹©è§†é¢‘æ–‡ä»¶"}), 400
    
#     file = request.files["video"]
#     task_id = str(uuid.uuid4())
#     input_path = os.path.join(UPLOAD_FOLDER, f"{task_id}.mp4")
#     output_path = os.path.join(OUTPUT_FOLDER, f"{task_id}.mp4")
    
#     file.save(input_path)
#     processing_progress[task_id] = 0
#     threading.Thread(
#         target=process_video, args=(input_path, output_path, task_id), daemon=True
#     ).start()
    
#     return jsonify({"code": 200, "msg": "ä¸Šä¼ æˆåŠŸ,å¼€å§‹æ£€æµ‹", "task_id": task_id})



# @api_model.route("/api/result/<task_id>", methods=["GET"]) # TODO
# def get_result(task_id):
#     # å®šä¹‰ç»“æœè§†é¢‘è·¯å¾„(ç»“åˆè¾“å‡ºæ–‡ä»¶å¤¹å’Œtask_idï¼‰
#     result_video_path = os.path.join(OUTPUT_FOLDER, f"{task_id}.mp4")
#     # æ„å»ºè§†é¢‘è·¯å¾„
#     result_path = os.path.join(OUTPUT_FOLDER, f"{task_id}.mp4")

#     # æ–°å¢ï¼šæ„å»ºCSVæ–‡ä»¶è·¯å¾„
#     csv_path = os.path.join(OUTPUT_FOLDER, f"{task_id}_target_timeline.csv")
    
#     # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
#     if not os.path.exists(result_path):
#         return jsonify({"code": 404, "msg": "ç»“æœè§†é¢‘æœªç”Ÿæˆ"}), 404
    
#     # æ–°å¢ï¼šåˆ¤æ–­CSVæ–‡ä»¶æ˜¯å¦å­˜åœ¨
#     csv_exists = os.path.exists(csv_path)
#     csv_url = f"/api/download_csv/{task_id}" if csv_exists else None  # åç»­å¯æ–°å¢ä¸‹è½½æ¥å£

#     # æ£€æŸ¥æ–‡ä»¶å¤§å°(æ’é™¤ç©ºæ–‡ä»¶ï¼‰
#     file_size = os.path.getsize(result_path)
#     if file_size < 1024:  # å°äº1KBè§†ä¸ºæ— æ•ˆæ–‡ä»¶
#         return jsonify({"code": 500, "msg": "è§†é¢‘æ–‡ä»¶æŸå"}), 500
    
#     # å¤„ç†Rangeè¯·æ±‚(æ–­ç‚¹ç»­ä¼ æ ¸å¿ƒé€»è¾‘ï¼‰
#     range_header = request.headers.get('Range', None)
#     if range_header:
#         # è§£æRangeå¤´éƒ¨(æ ¼å¼ç¤ºä¾‹ï¼šbytes=0-1023ï¼‰
#         try:
#             # æå–èµ·å§‹å’Œç»“æŸå­—èŠ‚
#             range_part = range_header.split('=')[1]
#             start_str, end_str = range_part.split('-')
#             start = int(start_str) if start_str else 0
#             end = int(end_str) if end_str else file_size - 1
            
#             # ç¡®ä¿ç»“æŸä½ç½®ä¸è¶…è¿‡æ–‡ä»¶å¤§å°
#             end = min(end, file_size - 1)
#             content_length = end - start + 1
            
#             # è¯»å–è§†é¢‘ç‰‡æ®µ
#             with open(result_path, 'rb') as f:
#                 f.seek(start)
#                 video_data = f.read(content_length)
            
#             # æ„å»º206éƒ¨åˆ†å†…å®¹å“åº”
#             response = make_response(video_data)
#             response.status_code = 206  # éƒ¨åˆ†å†…å®¹çŠ¶æ€ç 
#             response.headers['Content-Range'] = f'bytes {start}-{end}/{file_size}'
#             response.headers['Content-Length'] = str(content_length)
            
#         except Exception as e:
#             # è§£æRangeå¤±è´¥æ—¶è¿”å›å®Œæ•´æ–‡ä»¶
#             response = make_response(send_from_directory(OUTPUT_FOLDER, f"{task_id}.mp4"))
#     else:
#         # æ— Rangeè¯·æ±‚æ—¶è¿”å›å®Œæ•´æ–‡ä»¶
#         response = make_response(send_from_directory(OUTPUT_FOLDER, f"{task_id}.mp4"))
    

#         # æ–°å¢ï¼šåœ¨å“åº”å¤´æˆ–JSONä¸­è¿”å›CSVä¿¡æ¯(è‹¥ç”¨JSONè¿”å›,éœ€è°ƒæ•´æ¥å£é€»è¾‘,ç¤ºä¾‹å¦‚ä¸‹ï¼‰
#     # æ³¨ï¼šè‹¥ä¿æŒåŸæœ‰â€œè¿”å›è§†é¢‘æµâ€é€»è¾‘,å¯åœ¨å“åº”å¤´ä¸­æ·»åŠ CSVè·¯å¾„,æˆ–å•ç‹¬æ–°å¢ä¸‹è½½æ¥å£
#     # æ­¤å¤„ç¤ºä¾‹ä¸ºâ€œè¿”å›JSON+è§†é¢‘æµâ€çš„æ··åˆæ–¹å¼(å®é™…å¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
#     # (è‹¥ä»…éœ€è¿”å›è§†é¢‘æµ,å¯åˆ é™¤æ­¤éƒ¨åˆ†,ä»…åœ¨éœ€è¦æ—¶æä¾›CSVä¸‹è½½ï¼‰
#     response_data = {
#         "code": 200,
#         "msg": "success",
#         "video_url": f"/api/result/{task_id}",
#         "csv_exists": csv_exists,
#         "csv_url": csv_url
#     }

#      # æ­¤å¤„ä¿æŒåŸæœ‰è§†é¢‘æµè¿”å›,ä»…åœ¨æ—¥å¿—ä¸­æ‰“å°CSVä¿¡æ¯
#     print(f"ä»»åŠ¡ {task_id}ï¼šç»“æœè§†é¢‘è·¯å¾„ï¼š{result_video_path},CSVè·¯å¾„ï¼š{csv_path if csv_exists else 'æ— '}")
#     # å…³é”®å“åº”å¤´è®¾ç½®
#     response.headers['Content-Type'] = 'video/mp4'  # å›ºå®šè§†é¢‘MIMEç±»å‹
#     response.headers['Accept-Ranges'] = 'bytes'     # å‘ŠçŸ¥æµè§ˆå™¨æ”¯æŒæ–­ç‚¹ç»­ä¼ 
#     response.headers['Access-Control-Allow-Origin'] = '*'  # å…è®¸è·¨åŸŸ
    
#     return response


# @api_model.route("/api/download_csv/<task_id>", methods=["GET"]) # TODO
# def download_csv(task_id):
# # CSVæ–‡ä»¶è·¯å¾„(ä¸process_videoä¸­ç”Ÿæˆçš„è·¯å¾„ä¸€è‡´ï¼‰
#     csv_path = os.path.join(OUTPUT_FOLDER, f"{task_id}_target_timeline.csv")
#     print("csv_path",csv_path,)
#     # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
#     if not os.path.exists(csv_path) or os.path.getsize(csv_path) < 10:  # æ’é™¤ç©ºæ–‡ä»¶
#         return jsonify({"code": 404, "msg": "CSVæ–‡ä»¶ä¸å­˜åœ¨"}), 404
    
#     # å‘é€æ–‡ä»¶å¹¶è®¾ç½®ä¸‹è½½å“åº”å¤´
#     response = send_from_directory(
#         OUTPUT_FOLDER, 
#         f"{task_id}_target_timeline.csv",
#         as_attachment=True,  # å¼ºåˆ¶ä¸‹è½½
#         download_name=f"{task_id}_ç›®æ ‡æ—¶é—´è®°å½•.csv"  # ä¸‹è½½æ–‡ä»¶å
#     )
#     response.headers["Access-Control-Allow-Origin"] = "*"  # å…è®¸è·¨åŸŸ
#     return response

